---
title: "Quality Control"
author: "Will Hannon"
date: "1/11/2021"
output: html_document
---

This notebook contains an QC analysis of sequencing runs for the `SARS-CoV-2_Bottleneck` project. The main goals of this notebook are to characterize: 

1. Identify samples and regions of low-depth in the sequencing. 
2. Determine the contribution of extra sequencing to the quality of samples. 
3. Identify any oddities in the sequencing runs.

```{r Setup, include=FALSE}
require("knitr")
knitr::opts_chunk$set(echo = FALSE)
```

```{r Required Packages, message=FALSE, warning=FALSE, echo=FALSE}

## ==== Install Required Packages ==== ##

## List of all packages needed -- non-BioManager installed
packages = c("tidyverse", "scales")
## Check that packages are installed, if not, install them
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}
## Packages loading
invisible(lapply(c(packages), library, character.only = TRUE))

```

```{r Paths to data, echo = FALSE}

# Path to a processed data frame from the tool Multiqc.
# This isn't exhaustive for all QC data collated by this tool. 
# For a quick look at individual samples, there is also an HTML
# repot generated in the `results/qc` directory.
multiqc.data = "../../results/qc/formatted_multiqc_data.csv"
# Path to the data for what % of each library are filted out by BBduk
filter.data = "../../results/qc/BBduk_filtered_reads.csv"
# Path to sample information
sample.data = "../../config/samples.csv"
# Path to boat metadata
boat.data = "../../config/data/Boat_Sample_Metadata.csv"

```

```{r Load in data, echo = FALSE, message = FALSE}

# QC data from multiqc
multiqc.df = read_csv(multiqc.data)
# QC data from BBduk, collated separatley
filter.df = read_csv(filter.data) %>% mutate(library = as.character(library))
# Join the BBduk data with the multiqc data
qc.df = left_join(multiqc.df, filter.df, by = c("sample", "replicate", "library"))


# Sample and boat information
sample.df = read_csv(sample.data) %>% select(LibraryLayout, Virus, Host, Source, SpID ="spID") %>% distinct()

boat.df = read_csv(boat.data) 

metadata.df = full_join(boat.df, sample.df, by = "SpID") %>% 
  mutate(Included = if_else(is.na(Source), "Not Included", "Included"))

# Colors 
experiment.colors = c("#000000", "#7a7a7a")
```

Figure 1b. Shows a breakdown of all the passangers on the boat by the status of their avaliable data. According to the original paper (in section "Testing after ship returned due to outbreak."), RT-PCR testing data was avaliable for all 122 passengers upon return to shore. Of those 122 passengers, 101 tested positive within the first week + 10 days of return. The remaining three seroconverted and were considered infected on the ship. Of those 104 infections, 39 consensus genomes were assembled. 

```{r Donut, echo = F, message = F, warning = F, fig.width=6, fig.height=6, fig.align='center'}

donut.df = data.frame(Category = c("Negative", "Postive + Low Quality", "Positve + Deep-Sequenced"),
                      Count = c(18, 65, 39)) %>% 
  mutate(Freq = Count/sum(Count))

# Compute the cumulative percentages (top of each rectangle)
donut.df$ymax <- cumsum(donut.df$Freq)

# Compute the bottom of each rectangle
donut.df$ymin <- c(0, head(donut.df$ymax, n=-1))

# Compute label position
donut.df$labelPosition <- (donut.df$ymax + donut.df$ymin) / 2

ggplot(donut.df, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=Category)) +
  geom_rect() +
  geom_label(x=3.5, aes(y=labelPosition, label=Count), size=8) +
  scale_fill_brewer(palette=9) +
  coord_polar(theta="y") +
  xlim(c(2, 4)) +
  theme_void(35) +
  theme(legend.position = "none")

ggsave("../../config/figures/figure-1-B.svg", device = svg(), width = 5, height = 5)

```


Supplemental Figure 1a. The Ct values are shown for 72 samples collected from infected passangers of the boat that were avaliable for resequencing. Of those 72 samples, 24 met the stringent 20 Ct or lower cutoff for viral RNA levels. These samples were selected for our analysis. 

```{r Samples included by Ct, echo = F, message = F, warning = F, fig.width=11, fig.height=5, fig.align='center'}

metadata.df %>% 
  ggplot(aes(x = as.factor(reorder(SpID, -avg_ct)), y = avg_ct, col = Included)) + 
    geom_hline(yintercept = 20, col = "black", linetype = 2, size = 1.5) + 
    geom_point(size = 4) +
    annotate("text", x = 55, y = 25, label = paste0("N = ", length(filter(metadata.df, avg_ct <= 20)$SpID)), size = 11) + 
    xlab("Sample") + 
    ylab("Cycle Threshold (Ct)") + 
    scale_color_manual(values = c("#005AB5","#DC3220")) + 
    theme_classic(30) +
    theme(axis.text.x=element_blank(), 
          axis.ticks.x=element_blank(),
          legend.position = "none") 

```

Supplemental Figure 1b. Shows the number of reads comprising each individual library. There is a significant amount of variability between the library size of different replicates and samples. The median number of mapped reads was 1,113,690 per library/replicate. 

```{r Run Size, echo = FALSE, message = FALSE, fig.width=11, fig.height=5, fig.align='center'}

# The number of mapped reads for each sample. (1) correspond to the initial sequencing. (2) corresponds to the supplementary sequencing.
# `merged` corresponds to the combindation of the two libraries. 

median_lib_size = median(filter(qc.df, library == "merged")$reads_mapped)

qc.df %>% 
  filter(library == "merged") %>% 
  ggplot(aes(x = reorder(as.factor(sample), -reads_mapped), y = reads_mapped, fill = as.factor(replicate))) +
    geom_bar(stat = "identity", position = position_dodge()) + 
    geom_hline(yintercept = median_lib_size, col = "red") + 
    scale_fill_manual(values = experiment.colors, name = "Replicate") +
    xlab("Sample") +
    ylab("Number of Mapped Reads") +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=18)) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
    theme(axis.text.x=element_text(angle=45, hjust=1))

print(paste("The median library size is", median_lib_size, "reads."))
```

Supplemental Figure 1c. Shows the percent of the sample that deemed to belong to SARS-CoV-2 as opposed to some other organism. The percentage of reads that was filtered is pretty all over the place, with some samples nearly 100% SARS-CoV-2 and others closer to 5% SARS-CoV-2. There is also significant amount of difference between replicates. This highlights the importance of looking at replicates. 

```{r Percent Filtered replicates, echo = FALSE, message = FALSE, fig.width=11, fig.height=5, fig.align='center'}

qc.df %>%
  filter(library != "merged") %>% 
  group_by(sample, replicate) %>% 
  summarize(mean_percent_viral_reads = mean(percent_filtered_viral_reads)) %>% 
  ggplot(aes(x = as.factor(sample), y = mean_percent_viral_reads, fill = as.factor(replicate))) +
    geom_bar(stat = "identity", position = position_dodge()) + 
    scale_fill_manual(values = experiment.colors, name = "Replicate") +
    scale_y_continuous(labels = percent) + 
    xlab("Individual") +
    ylab("Percent SARS-CoV-2 Reads") +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=18)) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
    theme(axis.text.x=element_text(angle=45, hjust=1))

```

