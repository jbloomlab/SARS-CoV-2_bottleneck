---
output: html_document
---

##  SARS-CoV-2 Transmission Bottleneck Preliminary Analysis
```{r Setup, include=FALSE}
require("knitr")
knitr::opts_chunk$set(echo = FALSE)

## ==== Important file paths ==== ##

preprint.filepath =  "../../config/data/preprint_samples.csv" # Samples from pre-print
runselector.filepath =  "../../config/data/PRJNA610428.csv" # Samples from Bioproject
samples.filepath =  "../../config/samples.csv" # Samples that ran analysis
annotations.filepath = "../../config/data/sars_cov_2_annot.csv" # SARS-CoV-2 gene locations
multiqc.filepath = "../../config/data/multiQC-data.csv" # Data formatted from MultiQC
variant.filepath = "../../results/variant/variants.csv" # Combined Variant Calls
coverage.path = "../../results/split/" # Path to coverage data
```

```{r Required Packages, message=FALSE, warning=FALSE, echo=FALSE}

## ==== Install Required Packages ==== ##

## List of all packages needed -- non-BioManager installed
packages = c("tidyverse", "kableExtra", "gridExtra", "grid", "UpSetR", "ggridges", "ggpubr")
## Check that packages are installed, if not, install them
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}
## Packages loading
invisible(lapply(c(packages), library, character.only = TRUE))

```


### Overview

Hey Pavitra, we thought it'd be a good idea to share some of our thoughts and a preliminary analysis of the fishing boat data. Here is a summary of the main findings and the next steps. 

### Summary

So far, my analysis suggests that although there are shared variants between the samples from the fishing boat, there aren't substantially more than in the random control. These results highlight two key limitations; the lack of coverage in the boat samples and the absence of a comparable control group. By fixing both of these, it should be possible to estimate the amount of variation shared between individuals caused by the direct transmission of minor variants. 

### Questions

Here are some questions that we are thinking about: 

1. There are about 11 samples out of the 39 mentioned in the paper than I cannot track down on the UW Virology BioProject. Would you know who we could contact to locate these Accession numbers?

2. Are any of the samples in Supplemental Table 2 duplicates, i.e., collected from the same individual? 

3. I see that there is data on the Ct values of various samples in the Supplement, but I'm not sure how to connect this information to the sequencing runs. Is there a way to map these pieces of data to one another? 

4. Is 39 the total number of available samples, or are there more that could be sequenced (including samples collected from the same individual over time)? 

### Analysis
___
  
#### Samples 

For this analysis, I took all the available samples from the paper (28/39) and assembled a matched cohort of sequencing runs as a control. To keep the control group as similar as possible, I chose randomly from the UW Virology lab's BioProject after filtering for the same sequencing machine, library layout, and a similar library size (+/- 1 St.Dev).

#### Computational Workflow

Here, I'm showing the results from reads aligned with `BWA` and variants called with `Lofreq`. I filtered to keep variants that appear at greater than 2% frequency in at least one sample.   

```{r Data Formatting, echo=FALSE, message=FALSE, warning=FALSE, cache=T}
## ==== Read in the variant calls ==== ##
variant.df = read_csv(variant.filepath) %>%
      mutate(Test = case_when(startsWith(as.character(Accession), "SRR11939953-") ~ "Yes",
                 TRUE ~ "No"))

## ====  Import genome annotations ==== ##
annotations.df = read_csv(annotations.filepath)

# Get the interval positions for these genes 
ORF1ab = annotations.df %>% dplyr::filter(gene == "Orf1ab")
S = annotations.df %>% dplyr::filter(gene == "Spike")
ORF3a = annotations.df %>% dplyr::filter(gene == "ORF3a")
E = annotations.df %>% dplyr::filter(gene == "Envelope")
M = annotations.df %>% dplyr::filter(gene == "Membrane")
ORF6 = annotations.df %>% dplyr::filter(gene == "ORF6")
ORF7a = annotations.df %>% dplyr::filter(gene == "ORF7a")
ORF8 = annotations.df %>% dplyr::filter(gene == "ORF8")
N = annotations.df %>% dplyr::filter(gene == "Nucleocapsid")
ORF10 = annotations.df %>% dplyr::filter(gene == "ORF10")

# Rename genes for continuity
annotations.df = annotations.df %>% 
  mutate(gene = case_when(gene == "Orf1ab" ~ "ORF1ab",
                          gene == "Spike" ~ "Spike",
                          gene == "ORF3a" ~ "ORF3a",
                          gene == "Envelope" ~ "Envelope",
                          gene == "Membrane" ~ "Membrane",
                          gene == "ORF6" ~ "ORF6",
                          gene == "ORF7a" ~ "ORF7a",
                          gene == "ORF8" ~ "ORF8",
                          gene == "Nucleocapsid" ~ "Nucelocapsid",
                          gene == "ORF10" ~ "ORF10"))

# Add gene names to the variant.df
variant.df = variant.df %>% 
  mutate(Gene = case_when(POS < ORF1ab$start ~ "3'UTR",
                          POS >= ORF1ab$start & POS <= ORF1ab$end  ~ "ORF1ab",
                          POS >= S$start & POS <= S$end  ~ "Spike",
                          POS >= ORF3a$start & POS <= ORF3a$end  ~ "ORF3a",
                          POS >= E$start & POS <= E$end  ~ "Envelope",
                          POS >= M$start & POS <= M$end  ~ "Membrane",
                          POS >= ORF6$start & POS <= ORF6$end  ~ "ORF6",
                          POS >= ORF7a$start & POS <= ORF7a$end  ~ "ORF7a",
                          POS >= ORF8$start & POS <= ORF8$end  ~ "ORF8",
                          POS >= N$start & POS <= N$end  ~ "Nucelocapsid",
                          POS >= ORF10$start & POS <= ORF10$end  ~ "ORF10",
                          POS > ORF10$end ~ "5'UTR")) %>% 
  select(!c("LibraryLayout", "Virus", "Host", "Source", "Path")) %>% 
  mutate(ALT = ifelse(ALT == "True", "T", ALT)) %>% 
  mutate(Var_Type = case_when(nchar(REF) == 1 & nchar(ALT) == 1 ~ "SNP",
                              nchar(REF) > 1 ~ "Deletion",
                              nchar(ALT) > 1 ~ "Insertion")) %>% 
  mutate(SNP = paste0(REF,POS,ALT), Mutation = paste0(REF, ">", ALT)) %>% 
  filter(Aligner == "BWA", Caller == "lofreq", Var_Type == "SNP")


## ==== Get the Experiment that corresponds to each Accession ==== ##
experiment.table = variant.df %>% 
  select(Accession, Experiment, Bases, Test) %>% 
  distinct()

## ==== Remove SNPs that don't show up at 2% in at least 1 sample ==== ##
two.percent.snps = variant.df %>%
  filter(AF >= 0.02) %>%
  pull(SNP) %>%
  unique()

variant.df = variant.df[which(variant.df$SNP %in% two.percent.snps), ]
variant.df.test = variant.df %>% filter(Test == "Yes")
variant.df = variant.df %>% filter(Test == "No")
## ==== Import genome coverage files ==== ##

# Get paths to *.table output
coverage_file_paths = dir(path = coverage.path, pattern = "\\.coverage$", full.names = TRUE, recursive = TRUE)

# Make empty df to store coverage info
coverage.df = data.frame()

# Loop over all file paths
for (i in 1:length(coverage_file_paths)){

  # get path to file
  coverage.path = coverage_file_paths[i]

  # extract metadata from filepath
  coverage.info = strsplit(basename(coverage.path), "[.]")[[1]]
  coverage.name = coverage.info[1]
  coverage.aligner = coverage.info[2]

  # Read in the coverage file
  sample.coverage = read_tsv(coverage_file_paths[i],
                             col_names = c("Ref", "POS", "Coverage")) %>%
    mutate(Accession = coverage.name) %>%
    mutate(Aligner = coverage.aligner) %>%
    sample_n(., 10000, replace = F)

  # Combine the dataframes
  coverage.df = rbind(sample.coverage, coverage.df)
}

## ==== MultiQC summary DF ==== ##
# Get the % of reads mapped 
multiqc.df = read_csv(multiqc.filepath) %>% 
  left_join(., experiment.table, by = "Accession") %>%
  filter(Aligner == "BWA", Test == "No") %>% 
  mutate(SARS2 = Bases*Mapped)

## ==== Color and formatting ==== ##
# Experiment Colors
experiment.colors = c("#FFC20A", "#0C7BDC")
```

#### Run Quality

Here is an overview of the quality of the sequencing runs. In my experience, this has a significant impact on the variant calling and the number of minor variants identified. This figure shows some relevant quality metrics. The colors come from the cohort, whether the samples came from the fishing boat (`Cluster`) or the random group (`Control`)

```{r Quality Control, message=FALSE, warning=FALSE, echo=FALSE, fig.width=20, fig.height=8, fig.align='center'}

## == % mapping to reference == ##
mapped.plt = multiqc.df %>% 
  ggplot(aes(x = reorder(Accession, -Mapped), y = Mapped*100, fill = Experiment)) +
    geom_bar(stat = "identity", position = position_dodge()) +
    scale_fill_manual(values = experiment.colors) +
    xlab("Accession") +
    ylab("Percent") +
    ggtitle("Percentage of Reads Mapped") +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=13,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
    theme(axis.text.x=element_text(angle=45, hjust=1))

# Quick stats
lowqual = multiqc.df %>% 
  filter(Experiment == "Cluster", Mapped <= .5) %>% 
  nrow(.)
all = multiqc.df %>% 
  filter(Experiment == "Cluster") %>% 
  nrow(.)

## == Average coverage over the genome == ##
coverage.plt = coverage.df %>%
  filter(Aligner == "BWA") %>% 
  group_by(Accession) %>%
  summarize(mean_coverage = mean(Coverage)) %>%
  left_join(., experiment.table, by = "Accession") %>% filter(Test == "No") %>% 
  ggplot(aes(x = reorder(Accession, -mean_coverage), y = mean_coverage, fill = Experiment)) +
    geom_bar(stat = "identity", position = position_dodge()) +
    scale_fill_manual(values = experiment.colors) +
    xlab("Accession") +
    ylab("Mean Coverage") +
    ggtitle("Average Coverage per Sample" ) +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=13,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
    theme(axis.text.x=element_text(angle=45, hjust=1))


## == Relationship between coverage and minor variants called == ##

mean.coverage.df = coverage.df %>%
  filter(Aligner == "BWA") %>% 
  group_by(Accession) %>%
  summarize(mean_coverage = mean(Coverage)) 

rel.plt = variant.df %>% 
  filter(AF < 0.5, Experiment == "Cluster") %>% 
  group_by(Accession,Experiment) %>% 
  count() %>% 
  left_join(., mean.coverage.df, by = c('Accession')) %>% 
  ggplot(aes(x = n, y = mean_coverage)) + 
    geom_point(size = 2) +
    geom_smooth(method='lm', col = "red") + 
    stat_cor(method="pearson") +
    xlab("Number of Minor Variants Called") +
    ylab("Mean Coverage") +
    ggtitle("Minor SNPs v. Coverage" ) +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=18,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) 


grid.arrange(mapped.plt, coverage.plt, rel.plt, 
             layout_matrix = rbind(c(1, 1, 1, 3, 3),
                                   c(2, 2, 2, 3, 3)))

```

About `r round(lowqual/all*100, 2)` percent of samples had fewer than 50% of their reads map to the SARS-CoV-2 reference genome. This causes some samples to have low average coverage, which significantly lowers the power to detect minor variants. There is a strong relationship between the coverage of the fishing boat runs and the number of minor variants (<50% frequency) identified. 

I confirm this relationship below with a quick experiment. I randomly downsampled the number of reads from the sample with the highest ratio mean coverage (`SRR11939953`). Here, I'm plotting the number of reads against the number of variants called. The power to detect additional minor variants (between 2% and 50% frequency) tails off after about 2e6 starting reads. With a 70% mapping rate for this sample, we'd ideally aim for about 1.5e6 mapped reads per sample in future sequencing. 

```{r Library Size, message=FALSE, warning=FALSE, echo=FALSE, fig.width=5, fig.height=5, fig.align='center'}

variant.df.test %>% 
  filter(AF >= 0.02 & AF < 0.5) %>% 
  group_by(Accession, Bases) %>% 
  count() %>% 
  rename(Count = "n") %>% 
  ggplot(aes(x = Bases, y = Count)) +
    geom_point(size = 2) + 
    geom_line() +
    xlab("Read Count") +
    ylab("SNP Count") +
    ggtitle("SNPs(>= 2%) v. Coverage") + 
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=18,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed"))
  
```
 
#### Shared Variants

Finally, I wanted to see if there are more shared minor variants in the cluster of infections from the boat than in the control cohort. Ideally, the control should give us a sense of the magnitude of shared variation that is due to the direct transmission of minor variants instead of other factors.

First, I counted the number of SNPs shared between at least two individuals within each cohort and the number of SNPs unique to a single individual. I used fisher's exact test to see if the difference in ratios was statistically significant. 

```{r Fishers Exact Test, message=F, warning=F, echo=F}

shared.cluster = variant.df %>% 
  filter(Experiment == "Cluster", AF < 0.5) %>% 
  group_by(SNP) %>% 
  summarize(Count = n()) %>% 
  filter(Count >= 2) %>% 
  nrow(.)

shared.control = variant.df %>% 
  filter(Experiment == "Control", AF < 0.5) %>% 
  group_by(SNP) %>% 
  summarize(Count = n()) %>% 
  filter(Count >= 2) %>% 
  nrow(.)

unshared.cluster = variant.df %>% 
  filter(Experiment == "Cluster", AF < 0.5) %>% 
  group_by(SNP) %>% 
  summarize(Count = n()) %>% 
  filter(Count == 1) %>% 
  nrow(.)

unshared.control = variant.df %>% 
  filter(Experiment == "Control", AF < 0.5) %>% 
  group_by(SNP) %>% 
  summarize(Count = n()) %>% 
  filter(Count == 1) %>% 
  nrow(.)

contingency.df = data_frame(Experiment = c("Cluster", "Control"),
           Shared = c(shared.cluster, shared.control),
           Unique = c(unshared.cluster, unshared.control)) %>% 
  mutate(Ratio = Shared/Unique)


fsh.tst = fisher.test(matrix(c(shared.cluster,unshared.cluster,shared.control,unshared.control), ncol=2))

contingency.df %>%
  kable() %>%
  kable_styling()

print(fsh.tst)
```

The ratio of shared to unique SNPs is very similar between the cluster of infections and the control and is statistically insignificant. 

I also quantified the number shared minor variants in each cohort by counting how many SNPs are shared between any two samples in the same group. I did this for both the minor variants and major (>= 50%) variants. 

```{r Pairwise Comparison, message=F, warning=F, echo=F,fig.width=20, fig.height=8, fig.align='center'}

variant.cluster = variant.df %>% 
  filter(Experiment == "Cluster", AF < 0.5) 

varint.cluster.wide = variant.cluster %>% 
  select(SNP, Experiment, Accession) %>% 
  mutate(count = 1) %>%
  spread(Accession, count, fill = 0) 

variant.cluster.pairwise = variant.cluster %>% 
    pull(Accession) %>%
    unique() %>%
    combn(2) %>% 
    t() %>%
    as_data_frame() 

dat.cluster = data.frame()
for (i in 1:nrow(variant.cluster.pairwise)){
  # Get the combination
  combo = variant.cluster.pairwise[i,]
  # Caculate the number of shared variants
  V1 = varint.cluster.wide[,combo$V1]
  V2 = varint.cluster.wide[,combo$V2]
  shared = sum((V1+V2) == 2)
  # New row
  overlap.df = combo
  overlap.df$Count = shared
  # Bind rows
  dat.cluster = rbind(dat.cluster, overlap.df)
}
dat.cluster = dat.cluster %>% mutate(Experiment = "Cluster")
#### === Contol === ###

variant.control = variant.df %>% 
  filter(Experiment == "Control", AF < 0.5) 

variant.control.wide = variant.control %>% 
  select(SNP, Experiment, Accession) %>% 
  mutate(count = 1) %>%
  spread(Accession, count, fill = 0) 

variant.control.pairwise = variant.control %>% 
    pull(Accession) %>%
    unique() %>%
    combn(2) %>% 
    t() %>%
    as_data_frame() 

dat.control = data.frame()

for (i in 1:nrow(variant.control.pairwise)){
  # Get the combination
  combo = variant.control.pairwise[i,]
  # Caculate the number of shared variants
  V1 = variant.control.wide[,combo$V1]
  V2 = variant.control.wide[,combo$V2]
  shared = sum((V1+V2) == 2)
  # New row
  overlap.df = combo
  overlap.df$Count = shared
  # Bind rows
  dat.control = rbind(dat.control, overlap.df)
}
dat.control = dat.control %>% mutate(Experiment = "Control")

pairwise.df = rbind(dat.cluster, dat.control)

minor.plt = pairwise.df %>% 
  ggplot(aes(x = Count, fill = Experiment)) +
    geom_histogram(alpha = 0.5)  +
    xlab("Number Variants Shared Between Pair") +
    ylab("Count of Pairs") +
    ggtitle("Minor Variants") + 
    scale_fill_manual(values = experiment.colors) +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=18,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed"))


## ===== Major Variants ==== ##

variant.cluster.major = variant.df %>% 
  filter(Experiment == "Cluster", AF >= 0.5) 

varint.cluster.major.wide = variant.cluster.major %>% 
  select(SNP, Experiment, Accession) %>% 
  mutate(count = 1) %>%
  spread(Accession, count, fill = 0) 

variant.cluster.major.pairwise = variant.cluster.major %>% 
    pull(Accession) %>%
    unique() %>%
    combn(2) %>% 
    t() %>%
    as_data_frame() 

dat.cluster.major = data.frame()
for (i in 1:nrow(variant.cluster.major.pairwise)){
  # Get the combination
  combo = variant.cluster.major.pairwise[i,]
  # Caculate the number of shared variants
  V1 = varint.cluster.major.wide[,combo$V1]
  V2 = varint.cluster.major.wide[,combo$V2]
  shared = sum((V1+V2) == 2)
  # New row
  overlap.df = combo
  overlap.df$Count = shared
  # Bind rows
  dat.cluster.major = rbind(dat.cluster.major, overlap.df)
}
dat.cluster.major = dat.cluster.major %>% mutate(Experiment = "Cluster")
#### === Contol === ###

variant.control.major = variant.df %>% 
  filter(Experiment == "Control", AF > 0.5) 

variant.control.major.wide = variant.control.major %>% 
  select(SNP, Experiment, Accession) %>% 
  mutate(count = 1) %>%
  spread(Accession, count, fill = 0) 

variant.control.major.pairwise = variant.control.major %>% 
    pull(Accession) %>%
    unique() %>%
    combn(2) %>% 
    t() %>%
    as_data_frame() 

dat.control.major = data.frame()

for (i in 1:nrow(variant.control.major.pairwise)){
  # Get the combination
  combo = variant.control.major.pairwise[i,]
  # Caculate the number of shared variants
  V1 = variant.control.major.wide[,combo$V1]
  V2 = variant.control.major.wide[,combo$V2]
  shared = sum((V1+V2) == 2)
  # New row
  overlap.df = combo
  overlap.df$Count = shared
  # Bind rows
  dat.control.major = rbind(dat.control.major, overlap.df)
}
dat.control.major = dat.control.major %>% mutate(Experiment = "Control")

pairwise.major.df = rbind(dat.cluster.major, dat.control.major)

major.plt = pairwise.major.df %>% 
  ggplot(aes(x = Count, fill = Experiment)) +
    geom_histogram(alpha = 0.5)  +
    xlab("Number Variants Shared Between Pair") +
    ylab("Count of Pairs") +
    ggtitle("Major Variants") + 
    scale_fill_manual(values = experiment.colors) +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=18,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed"))

grid.arrange(minor.plt, major.plt, ncol = 2)

maj.table = pairwise.major.df %>% 
  group_by(Experiment) %>% 
  summarize(Mean = mean(Count), Median = median(Count)) %>%
  mutate(Variant = "Major Variants (>= 50%)")

min.table = pairwise.df %>% 
  group_by(Experiment) %>% 
  summarize(Mean = mean(Count), Median = median(Count)) %>%
  mutate(Variant = "Minor Variants (< 50%)")

rbind(min.table, maj.table) %>% 
  kable() %>% 
  kable_styling()
```

Unsurprisingly, more major variants are shared between pairs of samples from the boat than in the control group. Since we expect a single introduction caused most of the infections, this result makes sense. However, the opposite is observed for minor variants. It seems like pairs of samples from the control group share more minor variants than pairs of samples from the boat. This observation could result from lower average coverage and less power to detect variants in the fishing boat samples. 
















