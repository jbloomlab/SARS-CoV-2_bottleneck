---
title: "Downsampling Fastqs"
author: "Will Hannon"
date: "9/18/2020"
output: html_document
---

```{r Setup, include=FALSE}
require("knitr")
knitr::opts_chunk$set(echo = FALSE)

## ==== Important file paths ==== ##
multiqc.filepath = "../../config/data/2020-09-18_multiQC-data.csv" # QC data (manually prepared from MultiQC) from replicates
coverage.filepath = "../../results/split/merged.bedgraph" # Data on the average depth of coverage in 50 KB bins
variant.filepath = "../../results/variant/variants.csv" # Combined variant calls from varscan, lofreq, STAR, and BWA
pileup.filepath = "../../results/pileup/raw-variants.csv" # Variants identified from pileup files

```

```{r Required Packages, message=FALSE, warning=FALSE, echo=FALSE}

## ==== Install Required Packages ==== ##

## List of all packages needed -- non-BioManager installed
packages = c("tidyverse", "kableExtra", "gridExtra", "grid", "UpSetR", "ggridges", "ggpubr", "scales", "gplots")
## Check that packages are installed, if not, install them
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}
## Packages loading
invisible(lapply(c(packages), library, character.only = TRUE))

```

### Overview 

This notebook is to see the effect of depth on the variants called in each sample. 

```{r Data Import, echo=F, warning=F, message=F, cache=T}

## =============================================== ##
#
# This chunk contains code for importing and 
#  formatting the data used in the analysis.
#
## =============================================== ##

## =========== Import the variant calls ========== ##

# Filtering out everything but SNPs from Varscan/BWA
variant.df = read_csv(variant.filepath)  %>%
      mutate(Type = case_when(nchar(REF) < nchar(ALT) ~ "Insertion",
                              nchar(REF) > nchar(ALT) ~ "Deletion",
                              nchar(REF) == nchar(ALT) ~ "SNP")) %>% 
      filter(Aligner == "BWA", Caller == "varscan", Type == "SNP") %>% 
      separate(col = Accession, into = c("Accession", "Replicate", "Percent")) %>% 
      mutate(Replicate = ifelse(is.na(Replicate), 1, Replicate),
             SNP = paste0(REF, POS, ALT),
             Percent = ifelse(is.na(Percent), 100, Percent))

# Reshape the variant data to combine replicates
combined.df = full_join(filter(variant.df, Replicate == 1),
                        filter(variant.df, Replicate == 2),
                        by = c("Accession", "Percent", "POS", "REF", "ALT"),
                        suffix = c(".one", ".two")) %>% 
              select(!c("Replicate.one", "Replicate.two", "Aligner.one", "Aligner.two")) %>% 
              mutate_each(funs(replace(., which(is.na(.)), 0))) # Full Join, replace NA with 0

## =========== Import the run quality information ========== ##

multiqc.df = read.csv(multiqc.filepath) %>% 
  separate(col = Sample, into = c("Accession", "Aligner"), sep = "\\.") %>% 
  separate(col = Accession, into = c("Accession", "Replicate", "Percent"), sep = "-") %>% 
  mutate(Replicate = ifelse(is.na(Replicate), 1, Replicate)) %>% 
  mutate(Depth =(reads_mapped*average_length) / 29903) %>% 
  filter(Aligner == "BWA")  %>% 
  mutate(Percent = ifelse(is.na(Percent), 100, Percent))


## =========== Pileup statistics ========== ##

pileup.df = read_csv(pileup.filepath) %>% 
  select(!starts_with("Ins") & !starts_with("Del")) %>% 
  separate(col = Accession, into = c("Accession", "Replicate", "Percent"), sep = "-") %>% 
  mutate(Percent = ifelse(is.na(Percent), 100, Percent)) %>% 
  mutate(Replicate = ifelse(is.na(Replicate), 1, Replicate)) %>% 
  rename(REF = "Reference Base", CONS = "Consensus Base", POS = "Position") %>% 
  mutate(`A Total` = `A For` + `A Rev`,
         `C Total` = `C For` + `C Rev`,
         `T Total` = `T For` + `T Rev`,
         `G Total` = `G For` + `G Rev`) %>% 
  pivot_longer(cols = c("A For", "A Rev",
                        "C For", "C Rev",
                        "G For", "G Rev",
                        "T For", "T Rev",
                        "A Total", "C Total", "T Total", "G Total"),
               names_to = "ALT", values_to = "Count") %>% 
  separate(col = ALT, into = c("ALT", "Strand")) %>% 
  mutate(Strand = case_when(Strand == "For" ~ "+",
                            Strand == "Rev" ~  "-",
                            Strand == "Total" ~ "+/-"),
         SNP = paste0(REF, POS, ALT)) %>% 
  mutate(AF = Count/Depth, Type = case_when(ALT != REF ~ "SNP",
                                            ALT == REF ~ "REF")) %>% 
  filter(Type == "SNP")


# Reshape the variant data to combine replicates
combined.pileup.df = full_join(filter(pileup.df, Replicate == 1),
                                filter(pileup.df, Replicate == 2),
                                by = c("Accession", "Percent", "POS", "REF", "ALT", "CONS", "Strand"),
                                suffix = c(".one", ".two")) %>% 
  select(!c("Replicate.one", "Replicate.two")) %>% 
  filter(Strand == "+/-", AF.one > 0 & AF.two > 0) %>% 
  rename(DP.one = "Depth.one", DP.two = "Depth.two") %>% 
  mutate_each(funs(replace(., which(is.na(.)), 0))) # Full Join, replace NA with 0


## =========== Import the variant calls, keep indels ========== ##
# Keep only Varscan/BWA
variant.df.indels = read_csv(variant.filepath)  %>%
      mutate(Type = case_when(nchar(REF) < nchar(ALT) ~ "Insertion",
                              nchar(REF) > nchar(ALT) ~ "Deletion",
                              nchar(REF) == nchar(ALT) ~ "SNP")) %>% 
      filter(Aligner == "BWA", Caller == "varscan") %>% 
      separate(col = Accession, into = c("Accession", "Replicate", "Percent")) %>% 
      mutate(Replicate = ifelse(is.na(Replicate), 1, Replicate),
             SNP = paste0(REF, POS, ALT),
             Percent = ifelse(is.na(Percent), 100, Percent))

# Reshape the variant data to combine replicates
combined.df.indels = full_join(filter(variant.df.indels, Replicate == 1),
                        filter(variant.df.indels, Replicate == 2),
                        by = c( "Accession", "POS", "REF", "ALT"),
                        suffix = c(".one", ".two")) %>% 
              select(!c("Replicate.one", "Replicate.two", "Aligner.one", "Aligner.two"))  %>% 
              mutate_each(funs(replace(., which(is.na(.)), 0))) # Full Join, replace NA with 0

```

```{r}

true.consensus = c("A23403G", "C1059T",  "C14408T", "C241T",   "C3037T",  "G25563T", "G11083T")

# Mask the consensus SNPs
combined.df = combined.df[which(!combined.df$SNP.one %in% true.consensus),]
variant.df = variant.df[which(!variant.df$SNP %in% true.consensus),]
combined.pileup.df = combined.pileup.df[which(!combined.pileup.df$SNP.one %in% true.consensus),]
combined.df.indels = combined.df.indels[which(!combined.df.indels$SNP.one %in% true.consensus),]

```

```{r Variant Comparison, echo=F, warning=F, message=F, fig.width=10, fig.height=40, fig.align='center'}
# Raw variant frequencies with line of best fit and correlation coeff.
combined.df$Percent = factor(combined.df$Percent, levels = c("25", "50", "75", "100"))
  
combined.df %>% 
  ggplot(aes(x = (AF.one), y = (AF.two), group = Percent, col = Percent)) + 
    facet_grid(rows = vars(Accession), cols = vars(Percent)) +
    geom_point(col = "#525252") +
    geom_smooth(method='lm', se = F) + 
    stat_cor(method="pearson") +
    xlab("Allele Frequency Replicate One (Log10)") +
    ylab("Allele Frequency Replicate Two (Log10)") +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=18,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) + 
    theme(panel.background = element_rect(fill = NA, color = "black"))

```





