---
title: "Replicate Comparison Summary"
author: "Will Hannon"
date: "9/13/2020"
output: html_document
---

```{r Setup, include=FALSE}
require("knitr")
knitr::opts_chunk$set(echo = FALSE)

## ==== Important file paths ==== ##
multiqc.filepath = "../../../config/data/2020-08-07_multiQC-data.csv" # QC data (manually prepared from MultiQC) from replicates
coverage.filepath = "../../../config/data/2020-09-15_merged.bedgraph" # Data on the average depth of coverage in 50 KB bins
variant.filepath = "../../../config/data/2020-09-15_variants.csv" # Combined variant calls from varscan, lofreq, STAR, and BWA
pileup.filepath = "../../../config/data/2020-09-15_raw-variants.csv" # Variants identified from pileup files

```

```{r Required Packages, message=FALSE, warning=FALSE, echo=FALSE}

## ==== Install Required Packages ==== ##

## List of all packages needed -- non-BioManager installed
packages = c("tidyverse", "kableExtra", "gridExtra", "grid", "UpSetR", "ggridges", "ggpubr", "scales", "gplots")
## Check that packages are installed, if not, install them
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}
## Packages loading
invisible(lapply(c(packages), library, character.only = TRUE))

```

### Overview 

This notebook aims to assess our ability to call genomic variants accurately by comparing replicate sequencing runs. 

The samples consist of 24 sequencing runs with a Ct value of less than 20. Originally, samples were sequenced once as part of [this study](https://doi.org/10.1101/2020.08.13.20173161). The runs with a low enough Ct value to be considered for re-sequencing by a shotgun metagenomic method were re-sequenced as replicates. One sample is currently excluded from this analysis because it is not included on the SRA (`SpID: 10110`), leaving 23 final samples.

By comparing the allele frequency of variants called in both replicates, we hope to assess the accuracy, the optimal frequency cutoff, and the optimal coverage cutoff for downstream bottleneck analyses. 

### Replicate Information

The critical difference between the replicates is the processing. The samples on the SRA underwent a slightly different pre-processing pipeline to remove human reads and trim adaptors. Eventually, I'll re-process the raw files to make the pipelines identical. 

### Variant Calling 

For this preliminary analysis, I identified variants by two methods. First, I aligned the samples with `BWA`, and called variants with `Varscan` (I removed any filters for minimum allele frequency, depth, or supporting reads). Second, I identified each base at every position in the genome, and it's location on either the forward or reverse strand using `Samtools mpileup`. 

```{r Data Import, echo=F, warning=F, message=F}

## =============================================== ##
#
# This chunk contains code for importing and 
#  formatting the data used in the analysis.
#
## =============================================== ##

## =========== Import the variant calls ========== ##

# Filtering out everything but SNPs from Varscan/BWA
variant.df = read_csv(variant.filepath)  %>%
      mutate(Type = case_when(nchar(REF) < nchar(ALT) ~ "Insertion",
                              nchar(REF) > nchar(ALT) ~ "Deletion",
                              nchar(REF) == nchar(ALT) ~ "SNP")) %>% 
      filter(Aligner == "BWA", Caller == "varscan", Type == "SNP") %>% 
      separate(col = Accession, into = c("Accession", "Replicate")) %>% 
      mutate(Replicate = ifelse(is.na(Replicate), 1, Replicate),
             SNP = paste0(REF, POS, ALT))

# Reshape the variant data to combine replicates
combined.df = full_join(filter(variant.df, Replicate == 1),
                        filter(variant.df, Replicate == 2),
                        by = c( "Accession", "POS", "REF", "ALT"),
                        suffix = c(".one", ".two")) %>% 
              select(!c("Replicate.one", "Replicate.two", "Aligner.one", "Aligner.two")) %>% 
              mutate_each(funs(replace(., which(is.na(.)), 0))) # Full Join, replace NA with 0

## =========== Import the run quality information ========== ##

multiqc.df = read.csv(multiqc.filepath) %>% 
  separate(col = Sample, into = c("Accession", "Aligner"), sep = "\\.") %>% 
  separate(col = Accession, into = c("Accession", "Replicate"), sep = "-") %>% 
  mutate(Replicate = ifelse(is.na(Replicate), 1, Replicate)) %>% 
  mutate(Depth =(reads_mapped*average_length) / 29903) %>% 
  filter(Aligner == "BWA") 


## =========== Coverage ========== ##

coverage.df = read.delim(coverage.filepath) %>% 
  mutate(POS = (Stop-Start)/2 + Start, BinSize = Stop-Start) %>% 
  separate(col = Accession, into = c("Accession", "Replicate"), sep = "-")  %>% 
  mutate(Replicate = ifelse(is.na(Replicate), 1, Replicate)) %>% 
  filter(POS < 29850) # Filtering out the last 53 bases becuase of Poly-A

## =========== Pileup statistics ========== ##

pileup.df = read_csv(pileup.filepath)  %>% 
  select(!starts_with("Ins") & !starts_with("Del")) %>% 
  separate(col = Accession, into = c("Accession", "Replicate"), sep = "-")  %>% 
  mutate(Replicate = ifelse(is.na(Replicate), 1, Replicate)) %>% 
  rename(REF = "Reference Base", CONS = "Consensus Base", POS = "Position") %>% 
  mutate(`A Total` = `A For` + `A Rev`,
         `C Total` = `C For` + `C Rev`,
         `T Total` = `T For` + `T Rev`,
         `G Total` = `G For` + `G Rev`) %>% 
  pivot_longer(cols = c("A For", "A Rev",
                        "C For", "C Rev",
                        "G For", "G Rev",
                        "T For", "T Rev",
                        "A Total", "C Total", "T Total", "G Total"),
               names_to = "ALT", values_to = "Count") %>% 
  separate(col = ALT, into = c("ALT", "Strand")) %>% 
  mutate(Strand = case_when(Strand == "For" ~ "+",
                            Strand == "Rev" ~  "-",
                            Strand == "Total" ~ "+/-"),
         SNP = paste0(REF, POS, ALT)) %>% 
  mutate(AF = Count/Depth, Type = case_when(ALT != REF ~ "SNP",
                                            ALT == REF ~ "REF")) %>% 
  filter(Type == "SNP")


# Reshape the variant data to combine replicates
combined.pileup.df = full_join(filter(pileup.df, Replicate == 1),
                                filter(pileup.df, Replicate == 2),
                                by = c( "Accession", "POS", "REF", "ALT", "CONS", "Strand"),
                                suffix = c(".one", ".two")) %>% 
  select(!c("Replicate.one", "Replicate.two")) %>% 
  filter(Strand == "+/-", AF.one > 0 & AF.two > 0) %>% 
  rename(DP.one = "Depth.one", DP.two = "Depth.two") %>% 
  mutate_each(funs(replace(., which(is.na(.)), 0))) # Full Join, replace NA with 0


## =========== Import the variant calls, keep indels ========== ##
# Keep only Varscan/BWA
variant.df.indels = read_csv(variant.filepath)  %>%
      mutate(Type = case_when(nchar(REF) < nchar(ALT) ~ "Insertion",
                              nchar(REF) > nchar(ALT) ~ "Deletion",
                              nchar(REF) == nchar(ALT) ~ "SNP")) %>% 
      filter(Aligner == "BWA", Caller == "varscan") %>% 
      separate(col = Accession, into = c("Accession", "Replicate")) %>% 
      mutate(Replicate = ifelse(is.na(Replicate), 1, Replicate),
             SNP = paste0(REF, POS, ALT))

# Reshape the variant data to combine replicates
combined.df.indels = full_join(filter(variant.df.indels, Replicate == 1),
                        filter(variant.df.indels, Replicate == 2),
                        by = c( "Accession", "POS", "REF", "ALT"),
                        suffix = c(".one", ".two")) %>% 
              select(!c("Replicate.one", "Replicate.two", "Aligner.one", "Aligner.two"))  %>% 
              mutate_each(funs(replace(., which(is.na(.)), 0))) # Full Join, replace NA with 0

```

### Depth of Coverage

I think that one of the limiting factors in this analysis is the lack of coverage and the disparity in coverage between replicates. I'm not sure if this difference is due to pre-processing or random variation from re-sequencing. 

Below, I'm comparing the difference in the number (and %) of mapped reads between replicates. There are some substantial differences between replicates. 

```{r Mapped Reads , echo=F, message=F, warning=F, fig.width=15, fig.height=7, fig.align='center'}

## ==== Plot the mapped reads per sample ==== ##

reads.mapped.plt = multiqc.df %>% 
  ggplot(aes(x = reorder(Accession, -reads_mapped), y = reads_mapped, fill = Replicate)) +
    geom_bar(stat = "identity", position = position_dodge()) +
    scale_fill_manual(values = c("#3271a8", "#bf6021")) + 
    scale_y_continuous(label=scientific_format()) +
    xlab("Accession") +
    ylab("Reads Mapped") +
    ggtitle("Number of Mapped Reads per Sample" ) +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=13,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
    theme(axis.text.x=element_text(angle=30, hjust=1))

  
## ==== Plot the % of mapped reads per sample ==== ##

prec.reads.mapped.plt =  multiqc.df %>% 
  ggplot(aes(x = reorder(Accession, -reads_mapped_percent), y = reads_mapped_percent, fill = Replicate)) +
    geom_bar(stat = "identity", position = position_dodge()) +
    scale_fill_manual(values = c("#3271a8", "#bf6021")) + 
    xlab("Accession") +
    ylab("Reads Mapped (%)") +
    ggtitle("Percent of Mapped Reads per Sample" ) +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=13,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
    theme(axis.text.x=element_text(angle=30, hjust=1))

## ==== Join the plots together ==== ##
grid.arrange(reads.mapped.plt, prec.reads.mapped.plt, 
             layout_matrix = rbind(c(1, 1, 2, 2),
                                   c(1, 1, 2, 2)))
```

There is also a pronounced disparity in the patterns of coverage over the genome between replicates. Below, I've plotted the depth of coverage in 50 Kb bins over the genome. I filtered out the last 53 bp (2 bins) of the genome because there is a poly-A track with a tremendous amount of reads that align, which skews the visualization. I will figure out a way to handle these alignments. 

```{r Coverage, echo=F, message=F, warning=F, fig.width=15, fig.height=7, fig.align='center'}
coverage.df %>% 
  ggplot(aes(x = POS, y = Depth, col = Replicate)) + 
    geom_line() + 
    facet_wrap(~Accession) +
    scale_y_continuous(labels=label_scientific()) +
    scale_color_manual(values = c("#3271a8", "#bf6021")) + 
    xlab("Position") +
    ylab("Depth of Coverage") +
    ggtitle("Mean Depth of Coverage over the Genome" ) +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=13,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) 

```

Also, interestingly, there is a clear pattern of coverage over the genome in the second replicate (blue) that doesn't seem so evident in the first. I'm not sure what to make of this yet. Perhaps this pattern is a consequence of using a different pre-processing pipeline than the SRA replicates.

```{r Coverage Pattern, echo=F, message=F, warning=F, fig.width=15, fig.height=7, fig.align='center'}

coverage.df %>% 
  ggplot(aes(x = POS, y = (Depth), col = Replicate, group = Accession)) + 
    geom_line() + 
    facet_wrap(~Replicate) +
    scale_y_continuous(labels=label_scientific()) +
    scale_color_manual(values = c("#3271a8", "#bf6021")) + 
    xlab("Position") +
    ylab("Depth of Coverage") +
    ggtitle("Mean Depth of Coverage over the Genome" ) +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=13,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) 

```


### Consensus Variants

Next, I wanted to identify and remove all consensus variants shared between the samples. Optimally, I could do this in the analysis pipeline upstream of the final alignment. However, by identifying consensus variants at this stage, I can check for any systematic biases or samples that might skew the cohort's consensus sequence by having a replicate with too little depth over a region. 

To identify consensus variants, I filtered for any variants that appear at greater than or equal to 50% frequency in either replicate and counted the number of samples with these variants. 

```{r Consensus Variants, echo=F, warning=F, message=F, fig.width=5, fig.height=5, fig.align='center'}

## ==== Determine the variants present in every sample ==== ##
consensus.df = combined.df %>% 
  filter(AF.one >= 0.5 | AF.two >= 0.5 ) %>% 
  select(SNP.one, Accession) %>% 
  group_by(SNP.one) %>% 
  summarize(Count = n()) %>% 
  arrange(-Count) %>% 
  mutate(Consesus = case_when(Count == 23 ~ "Yes",
                              Count >= 21 ~ "Almost",
                              Count < 21 ~ "No")) 

## ==== Visually represent this ==== ##
consensus.df %>% 
  ggplot(aes(x = reorder(SNP.one, -Count), y = Count, fill = Consesus)) + 
    geom_bar(stat = "identity", position = position_dodge()) +
    scale_fill_manual(values = c("#dfe615", "#757575", "#b51714")) + 
    xlab("SNP") +
    ylab("Number of Samples") +
    ggtitle("Consensus Variants" ) +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=13,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) + 
    theme(legend.position = "none")

```

There are two SNPs (indicated in Red) that show up in all 23 samples. There are another ~7 SNPs that are likely consensus variants, but are missing from either one or two samples (or replicates). 

I was curious if these SNPs present in 21 or 22 samples were genuinely absent from the remaining samples. I checked if there was a bias in what samples were missing consensus variants. 

```{r Missing Consensus, echo=F, warning=F, message=F}

## ==== Is there a systematic bais in the samples here? ==== ##

consensus.snps = filter(consensus.df, Count >= 21 & Count < 23 )$SNP.one

for (i in 1:length(consensus.snps)){
  # Get the SNP
  snp = consensus.snps[i]
  
  # == Determine the sample or samples missing this SNP == #
  
  # All accessions
  accessions = unique(combined.df$Accession)
  
  # Accessions that have this SNP
  snp.accessions = unique(filter(combined.df, SNP.one == snp)$Accession)
  
  # Which accessions aren't included?
  print(paste(snp, accessions[!accessions %in% snp.accessions], sep = "-"))

}
```

There are two samples (`SRR11939959` and `SRR11939986`) that are missing three and four variants respectivley. 

```{r Missing Consensus Vallidation, echo=F, warning=F, message=F}
## ==== Check if these samples are only missing variants in one of the replicates ==== ##

ct.df = combined.df %>% select(Accession, Avg_Ct = "avg_ct.one") %>% distinct() %>% filter(Avg_Ct != 0)

missing.sampels = c("SRR11939959", "SRR11939986", "SRR11939958")

multiqc.df[which(multiqc.df$Accession %in% missing.sampels),] %>% 
  left_join(., ct.df) %>% 
  select(Accession, Replicate, `Reads Mapped` = "reads_mapped", `Percent Mapped` = "reads_mapped_percent", `Average Ct` = "Avg_Ct") %>% 
  kable(caption = "Samples Missing Consensus Variants") %>%
  kable_styling(bootstrap_options = c("striped")) 

```

Samples `SRR11939959` and `SRR11939986` have at least one replicate with a very low percentage of reads mapped. The following SNPs were excluded becuase they were missing from a single replicate: 

- `A23403G`
- `C14408T`
- `C241T`
- `G25563T`
- `G11083T`

These SNPs do appear to be true consensus SNPs. Two SNPs are genuinely missing from both replicates of `SRR11939986` and can't be easily explained by low coverage:

- `C7564T`
- `G28376T`

Therefore, the following 7 SNPs are the true consensus SNPs and should be masked from downstream analyses. 
```{r True Consensus SNPs, echo=F, warning=F, message=F}

## ==== Manually select the true consensus SNPs ==== ##

true.consensus = filter(consensus.df, Count >= 21)[which(!filter(consensus.df, Count >= 21)$SNP.one %in% c("C7564T", "G28376T")),]$SNP.one

print(true.consensus)

# Mask the consensus SNPs
combined.df = combined.df[which(!combined.df$SNP.one %in% true.consensus),]
variant.df = variant.df[which(!variant.df$SNP %in% true.consensus),]
combined.pileup.df = combined.pileup.df[which(!combined.pileup.df$SNP.one %in% true.consensus),]
combined.df.indels = combined.df.indels[which(!combined.df.indels$SNP.one %in% true.consensus),]

```

### Number of SNPs

Before I compare the SNPs called in the replicates, I wanted to see how many SNPs were called in each sample.

```{r Remove Samples, echo=F, warning=F, message=F, fig.width=10, fig.height=8, fig.align='center'}

## ==== Identify samples with too few variants ==== ##

varscan.plt = combined.df %>% 
  group_by(Accession) %>% 
  count() %>% 
  mutate(Color = ifelse(n <= 5, "0", "1")) %>% 
    ggplot(aes(x = reorder(Accession, -n), y = n, fill = Color)) + 
      geom_bar(stat = "identity", position = position_dodge()) +
      geom_hline(yintercept = 5, col = "#b51714", linetype = 2) + 
      scale_fill_manual(values = c("#b51714", "#757575")) + 
      xlab("Accession") +
      ylab("Number of SNPs") +
      ggtitle("Varscan SNPs" ) +
      theme_classic() +
      theme(legend.position="bottom", legend.box = "horizontal") +
      theme(legend.box.background = element_rect(colour = "black")) +
      theme(text=element_text(size=13,  family="mono")) +
      theme(plot.title = element_text(hjust = 0.5)) +
      theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
      theme(axis.text.x=element_text(angle = 30, hjust=1)) + 
      theme(legend.position = "none")


varscan.indels.plt = combined.df.indels %>% 
  group_by(Accession) %>% 
  count() %>% 
  mutate(Color = ifelse(n <= 5, "0", "1")) %>% 
    ggplot(aes(x = reorder(Accession, -n), y = n, fill = Color)) + 
      geom_bar(stat = "identity", position = position_dodge()) +
      geom_hline(yintercept = 5, col = "#b51714", linetype = 2) + 
      scale_fill_manual(values = c("#b51714", "#757575")) + 
      xlab("Accession") +
      ylab("Number of SNPs") +
      ggtitle("Varscan SNPs & InDels" ) +
      theme_classic() +
      theme(legend.position="bottom", legend.box = "horizontal") +
      theme(legend.box.background = element_rect(colour = "black")) +
      theme(text=element_text(size=13,  family="mono")) +
      theme(plot.title = element_text(hjust = 0.5)) +
      theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
      theme(axis.text.x=element_text(angle = 30, hjust=1)) + 
      theme(legend.position = "none")
  

pileup.plt = combined.pileup.df  %>% 
  group_by(Accession) %>% 
  count()  %>% 
  mutate(Color = ifelse(n <= 5, "0", "1")) %>% 
    ggplot(aes(x = reorder(Accession, -n), y = n, fill = Color)) + 
      geom_bar(stat = "identity", position = position_dodge()) +
      geom_hline(yintercept = 5, col = "#b51714", linetype = 2) + 
      scale_fill_manual(values = c( "#757575","#b51714")) + 
      xlab("Accession") +
      ylab("Number of SNPs") +
      ggtitle("Pileup SNPs" ) +
      theme_classic() +
      theme(legend.position="bottom", legend.box = "horizontal") +
      theme(legend.box.background = element_rect(colour = "black")) +
      theme(text=element_text(size=13,  family="mono")) +
      theme(plot.title = element_text(hjust = 0.5)) +
      theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
      theme(axis.text.x=element_text(angle = 30, hjust=1)) + 
      theme(legend.position = "none")


x = variant.df %>% 
  group_by(Accession) %>% 
  count() %>% 
  mutate(Method = "Varscan-SNP")

y = variant.df.indels %>% 
  group_by(Accession) %>% 
  count() %>% 
  mutate(Method = "Varscan-SNP/InDels")

z = pileup.df %>%
  filter(Strand == "+/-", AF > 0) %>% 
  group_by(Accession) %>% 
  count() %>% 
  mutate(Method = "Pileup-SNP")

mapped.df = multiqc.df %>% filter(Aligner == "BWA") 

correlation.plt = full_join(rbind(x,y,z), mapped.df) %>% 
    ggplot(aes(x = reads_mapped, y = log10(n), col = Method)) + 
      geom_point() +
      geom_smooth(se = F, method = "lm") +
      xlab("Mapped Reads") +
      ylab("SNPs Identified (Log10(count))") +
      ggtitle("Correlation between SNPs and Depth") +
      theme_classic() +
      theme(legend.position="bottom", legend.box = "horizontal") +
      theme(legend.box.background = element_rect(colour = "black")) +
      theme(text=element_text(size=13,  family="mono")) +
      theme(plot.title = element_text(hjust = 0.5)) +
      theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) 

## ==== Join the plots together ==== ##
grid.arrange(varscan.plt, 
             varscan.indels.plt,
             pileup.plt,
             correlation.plt,
             layout_matrix = rbind(c(1, 1, 2, 2),
                                   c(1, 1, 2, 2),
                                   c(3, 3, 4, 4),
                                   c(3, 3, 4, 4)))

```

There are three main takeaways from the above plots: 

1. There are significantly more variants shared between replicates called by the pileup file. 
2. About seven samples have fewer than five variants shared between replicates. 
3. There is a correlation between the number of mapped reads in each replicate and the number of SNPs in each method. 

### Replicate Comparison

Next, I wanted to assess the variability in the frequency of alternative alleles called in each replicate. Samples with significant variability likely have low viral template number and can be excluded from downstream analyses. Additionally, I should be able to determine which samples need to be sequenced to higher depth. 

First, I plotted the most simple case. Here are all of the SNPs called by `Varscan` excluding the seven consensus variants shared by all samples.

```{r Variant Comparison, echo=F, warning=F, message=F, fig.width=10, fig.height=10, fig.align='center'}

## ==== Plot alternative allele frequencies against each other ==== ##

# Raw variant frequencies with line of best fit and correlation coeff.
combined.df %>% 
  ggplot(aes(x = (AF.one), y = (AF.two))) + 
    facet_wrap(~Accession) +
    geom_smooth(method='lm', col = "red", se = F) + 
    stat_cor(method="pearson") +
    geom_point() +
    xlab("Allele Frequency Replicate One") +
    ylab("Allele Frequency Replicate Two") +
    ggtitle("Variation Between Replicate SNPs" ) +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=18,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) 

```

Several samples have nearly no variants shared between replicates at a frequency of less than ~1. These include the following samples: 

- `SRR11939954`
- `SRR11939959`
- `SRR11939997`
- `SRR11939998`

I labled these samples as the "Worst" quality replicates. Below is a table summarizing their depth and Ct. 

```{r Too Few Variants, echo=F, warning=F, message=F}
## ==== Check if these samples are only missing variants in one of the replicates ==== ##
low.variants.samples = c("SRR11939954", "SRR11939959", "SRR11939997", "SRR11939998")

multiqc.df[which(multiqc.df$Accession %in% low.variants.samples),] %>% 
  left_join(., ct.df) %>% 
  select(Accession, Replicate, `Reads Mapped` = "reads_mapped", `Percent Mapped` = "reads_mapped_percent", `Average Ct` = "Avg_Ct") %>% 
  kable(caption = "No Low Frequency Variants") %>%
  kable_styling(bootstrap_options = c("striped")) 

```

All four samples have relatively few reads mapped and in the case of `SRR11939959`, `SRR11939997`, and `SRR11939998` comparatively high Ct values (~19 cycles).

Otherwise, the main takeaway from the plot above is that there are few variants between low frequency (> 5%) and high frequency (> 90%). Also, as expected, high-frequency variants have good concordance between replicates. Therefore, it's easier to visualize with a log transformation.

```{r Variant Comparison Minor, echo=F, warning=F, message=F, fig.width=10, fig.height=10, fig.align='center'}

## ==== Plot alternative allele frequencies against each other ==== ##

# Raw variant frequencies with line of best fit and correlation coeff.
combined.df %>% 
  ggplot(aes(x = log10(AF.one), y = log10(AF.two))) + 
    facet_wrap(~Accession) +
    geom_smooth(method='lm', col = "red", se = F) + 
    stat_cor(method="pearson") +
    geom_point() +
    xlab("Allele Frequency Replicate One (Log10)") +
    ylab("Allele Frequency Replicate Two (Log10)") +
    ggtitle("Replicate AFs - Log") +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=18,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) 

```

Some samples have better concordance between allele frequencies than others. However, the relationship is easier to visualize with insertions and deletions included. 

```{r Variant Comparison Indels, echo=F, warning=F, message=F, fig.width=10, fig.height=10, fig.align='center'}

## ==== Plot alternative allele frequencies against each other ==== ##

# Raw variant frequencies with line of best fit and correlation coeff.
combined.df.indels %>% 
  ggplot(aes(x = log10(AF.one), y = log10(AF.two))) + 
    facet_wrap(~Accession) +
    geom_smooth(method='lm', col = "red", se = F) + 
    stat_cor(method="pearson") +
    geom_point() +
    xlab("Allele Frequency Replicate One (Log10)") +
    ylab("Allele Frequency Replicate Two (Log10)") +
    ggtitle("Replicate AFs - w/ InDels") +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=18,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) 

```

With this, I can break the samples into either "Good" or "Bad" quality groups. The "Bad" quality group excludes the "Worst" quality samples mentioned above.

```{r Sample Quality, echo=F, message=F, warning=F}

all.samples = unique(variant.df$Accession)
  
good.samples = c("SRR11939953", "SRR11939957", "SRR11939987", 
                 "SRR11939988", "SRR11939989", "SRR11939990", 
                 "SRR11939991", "SRR11939992", "SRR11939999")

worst.samples = c("SRR11939954", "SRR11939959", "SRR11939997", "SRR11939998")

bad.samples = all.samples[which(!all.samples %in% c(good.samples, worst.samples))]

# good.df = multiqc.df[which(multiqc.df$Accession %in% good.samples),] %>% 
#   mutate(Quality = "Good")
# 
# bad.df = multiqc.df[which(multiqc.df$Accession %in% bad.samples),] %>% 
#   mutate(Quality = "Bad")
# 
# worst.df = multiqc.df[which(multiqc.df$Accession %in% worst.samples),] %>% 
#   mutate(Quality = "Worst")

```

### Pileup Variants

Finally, I wanted to see if these relationships hold when I include the variants I identified with `mpileup`. Below, these variants are layered over the variants called by `Varscan`. The line showing the relationship between allele frequencies is drawn for the `Varscan` SNPs and is colored by the sample-quality mentioned above. 

```{r Pileup Comparison, echo=F, warning=F, message=F, fig.width=10, fig.height=10, fig.align='center'}

effect_colors = c("#e2e627", "#13a13b","#990505")

identity.df = combined.df %>% mutate(Identity = paste0(Accession, SNP.one))

combined.pileup.df.plotting = combined.pileup.df %>% 
  mutate(Quality = as.factor(case_when(Accession %in% good.samples ~ "Good",
                                       Accession %in% bad.samples ~ "Bad",
                                       Accession %in% worst.samples ~ "Worst"))) %>% 
  mutate(Identity = paste0(Accession, SNP.one)) %>% 
  mutate(Shared = case_when(Identity %in% identity.df$Identity ~ "Shared",
                            !Identity %in% identity.df$Identity ~ "Unique"))

ggplot() + 
  geom_point(data = filter(combined.pileup.df.plotting, Shared == "Unique"), aes(x = (AF.one), y = (AF.two)),col = "grey", alpha = 0.7) +
  geom_point(data = filter(combined.pileup.df.plotting, Shared == "Shared"), aes(x = (AF.one), y = (AF.two)), col = "red") +
  geom_smooth(data = filter(combined.pileup.df.plotting, Shared == "Shared"), aes(x = (AF.one), y = (AF.two), col = Quality), method='lm', se = F) + 
  stat_cor(data = filter(combined.pileup.df.plotting, Shared == "Shared"), aes(x = (AF.one), y = (AF.two), col = Quality), method="pearson") +
  facet_wrap(~Accession) +
  scale_color_manual(values = effect_colors) + 
  xlab("Allele Frequency Replicate One") +
  ylab("Allele Frequency Replicate Two") +
  ggtitle("Variation Between Replicates - Pileup" ) +
  theme_classic() +
  theme(legend.position="bottom", legend.box = "horizontal") +
  theme(legend.box.background = element_rect(colour = "black")) +
  theme(text=element_text(size=18,  family="mono")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
  theme(axis.text.x=element_text(angle=45, hjust=1)) 

```

"Bad" and "Worst" quality replicates do not have concordant allele frequencies. However, it's not clear for all samples, so  I log-transformed the axes hoping to get a better sense. 

```{r Log Pileup Comparison, echo=F, warning=F, message=F, fig.width=10, fig.height=10, fig.align='center'}

ggplot() + 
  geom_point(data = filter(combined.pileup.df.plotting, Shared == "Unique"), aes(x = log10(AF.one), y = log10(AF.two)),col = "grey", alpha = 0.7) +
  geom_point(data = filter(combined.pileup.df.plotting, Shared == "Shared"), aes(x = log10(AF.one), y = log10(AF.two)), col = "red") +
  geom_smooth(data = filter(combined.pileup.df.plotting, Shared == "Shared"), aes(x = log10(AF.one), y = log10(AF.two), col = Quality), method='lm', se = F) + 
  stat_cor(data = filter(combined.pileup.df.plotting, Shared == "Shared"), aes(x = log10(AF.one), y = log10(AF.two), col = Quality), method="pearson") +
  facet_wrap(~Accession) +
  scale_color_manual(values = effect_colors) + 
  xlab("Allele Frequency Replicate One (Log10)") +
  ylab("Allele Frequency Replicate Two (Log10)") +
  ggtitle("Variation Between Replicates - Pileup" ) +
  theme_classic() +
  theme(legend.position="bottom", legend.box = "horizontal") +
  theme(legend.box.background = element_rect(colour = "black")) +
  theme(text=element_text(size=18,  family="mono")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
  theme(axis.text.x=element_text(angle=45, hjust=1)) 
```

There is a pretty significant amount of variability regardless of the concordance between allele frequencies called by `Varscan`. The alleles annotated in the pileup statistics are possible too lenient since I haven't applied any filters. I noticed by looking at the data that variants shared between `mpileup` and `Varscan` have at least seven supporting reads in each replicate. This number isn't hardcoded into the variant calling by `Varscan`, but is probably a consequence of the maximum coverage. From looking at the manual for Varscan, that's the only explanation that I have. 

I applied the filter that any allele must be supported by at least 7 reads in either replicate. The remaining alleles show pretty good concordance, even the variants only called from the pileup file. 

```{r Log Pileup Comparison filtered, echo=F, warning=F, message=F, fig.width=10, fig.height=10, fig.align='center'}

combined.pileup.df.plotting %>% 
  filter(Count.one >= 7 & Count.two >= 7) %>% 
  #filter(AF.one < 0.5 & AF.two < 0.5) %>% 
  ggplot(aes(x = log10(AF.one), y = log10(AF.two))) + 
  geom_point(col = "grey", alpha = 0.7) +
  geom_point(data = filter(combined.pileup.df.plotting, Shared == "Shared"), aes(x = log10(AF.one), y = log10(AF.two)), col = "red") +
  geom_smooth(data = filter(combined.pileup.df.plotting, Shared == "Shared"), aes(x = log10(AF.one), y = log10(AF.two), col = Quality), method='lm', se = F) + 
  stat_cor(data = filter(combined.pileup.df.plotting, Shared == "Shared"), aes(x = log10(AF.one), y = log10(AF.two), col = Quality), method="pearson") +
  facet_wrap(~Accession) +
  scale_color_manual(values = effect_colors) + 
  xlab("Allele Frequency Replicate One (Log10)") +
  ylab("Allele Frequency Replicate Two (Log10)") +
  ggtitle("Variation Between Replicates - Pileup" ) +
  theme_classic() +
  theme(legend.position="bottom", legend.box = "horizontal") +
  theme(legend.box.background = element_rect(colour = "black")) +
  theme(text=element_text(size=18,  family="mono")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) +
  theme(axis.text.x=element_text(angle=45, hjust=1))
  

```

### How to Proceed?

Samples with very few variants fall both into the "Worst" and "Bad" categories. Since these samples have so few variants, they can't be assessed based on the variability in allele frequency. The only way to remedy this is to sequence more. However, since most of the "Worst" samples have relatively high Ct values, this might be futile. These samples are as follows: 

- SRR11939954
- SRR11939958
- SRR11939959
- SRR11939984
- SRR11939986
- SRR11939997
- SRR11939998
- SRR11940000
- SRR11940002
- SRR11940006

Next are the samples with comparatively many shared variants. Of these, four have a similar number of variants to the "Good" samples, but more variability. These are the samples I assume have low template diversity. These samples are: 

- SRR11939993
- SRR11939994
- SRR11940004
- SRR11940005

Finally, there are the "Good" samples that probably don't need much more re-sequencing: 

- SRR11939953
- SRR11939957
- SRR11939987
- SRR11939988
- SRR11939989
- SRR11939990
- SRR11939991
- SRR11939992
- SRR11939999

The worst samples have low depth and high Ct. The best samples have high depth and low Ct. With a better statistic for variability than manually binning the runs into categories, it should be easier to correlate the depth and Ct with the replicates' accuracy. Effective depth should accomplish this. 

```{r Quality Correlates, echo=F, warning=F, message=F, fig.width=7, fig.height=5, fig.align='center'}


multiqc.df %>% 
  mutate(Quality = as.factor(case_when(Accession %in% good.samples ~ "Good",
                                       Accession %in% bad.samples ~ "Bad",
                                       Accession %in% worst.samples ~ "Worst"))) %>% 
  left_join(., ct.df) %>% 
  ggplot(aes(x = Depth, y = Avg_Ct, col = Quality)) + 
    geom_point(size = 2.5)  +
    scale_color_manual(values = effect_colors) + 
    xlab("Average Depth") +
    ylab("Average Ct") +
    ggtitle("Correlates of Quality" ) +
    theme_classic() +
    theme(legend.position="bottom", legend.box = "horizontal") +
    theme(legend.box.background = element_rect(colour = "black")) +
    theme(text=element_text(size=18,  family="mono")) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme(panel.grid.major.y = element_line(colour="grey", linetype="dashed")) 


```

### Shared Variants

Using only the "Good" quality replicates, curious what the extent of shared variation was between samples. I used variants called by `Varscan` with coverage > 200X in both replicates and more that 7 supporting reads in both replicates. First, I made a matrix with the all of the variants. 

```{r Pairwise, echo=F, warning=F, message=F, fig.width=7, fig.height=7, fig.align='center'}

shared.all.df = combined.pileup.df.plotting %>% 
        filter(Quality == "Good",
               Shared == "Shared",
               DP.one > 200 & DP.two > 200,
               Count.one > 7 & Count.two > 7)

accessions.to.include = unique(shared.all.df$Accession)
results = data.frame()
for (i in 1:length(accessions.to.include)){
  for (j in 1:length(accessions.to.include)){
    accession.i = accessions.to.include[i]
    accession.j = accessions.to.include[j]
    variants.i = filter(shared.all.df, Accession == accession.i)$SNP.one
    variants.j = filter(shared.all.df, Accession == accession.j)$SNP.one
    sum.variants = length(variants.i) + length(variants.j)
    intersect = intersect(variants.i, variants.j)
    n_intersect = length(intersect)
    row = data.frame(accession.i, accession.j, n_intersect)
    results = rbind(results, row)
  }
}


all.df  = spread(results, accession.i, n_intersect)[,-1]
rownames(all.df) = spread(results, accession.i, n_intersect)[,1]
all.df = as.matrix(all.df)

heatmap.2(all.df, scale = "none", col = viridis_pal(), cellnote = round(all.df, 2), main= "All Variants",
          trace = "none", density.info = "none", cexRow=1,cexCol=1,margins=c(12,8),srtCol=45)


```

Then, I made a matrix with only the minor variants. 

```{r Pairwise Minor, echo=F, warning=F, message=F, fig.width=7, fig.height=7, fig.align='center'}
shared.df = combined.pileup.df.plotting %>% 
        filter(Quality == "Good",
               Shared == "Shared",
               DP.one > 200 & DP.two > 200,
               Count.one > 7 & Count.two > 7, 
               AF.one < 0.5 & AF.two < 0.5)

accessions.to.include = unique(shared.df$Accession)
results = data.frame()
for (i in 1:length(accessions.to.include)){
  for (j in 1:length(accessions.to.include)){
    accession.i = accessions.to.include[i]
    accession.j = accessions.to.include[j]
    variants.i = filter(shared.df, Accession == accession.i)$SNP.one
    variants.j = filter(shared.df, Accession == accession.j)$SNP.one
    sum.variants = length(variants.i) + length(variants.j)
    intersect = intersect(variants.i, variants.j)
    n_intersect = length(intersect)
    row = data.frame(accession.i, accession.j, n_intersect)
    results = rbind(results, row)
  }
}


df  = spread(results, accession.i, n_intersect)[,-1]
rownames(df) = spread(results, accession.i, n_intersect)[,1]
df = as.matrix(df)

heatmap.2(df, scale = "none", col = viridis_pal(), cellnote = round(df, 2), main="Minor Variants",
          trace = "none", density.info = "none", cexRow=1,cexCol=1,margins=c(12,8),srtCol=45)
```

The number of variants shared between samples has a lot to do with the number of variants the sample starts with. On average, samples shar about half of their variants with other samples. However, most of these are low frequency (< 1%). 








